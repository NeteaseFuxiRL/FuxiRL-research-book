# 游戏AI泛化性研究

## 课题背景

游戏AI的泛化能力对商业游戏至关重要。如果线上的AI被人类玩家找到弱点，可能给公司造成巨大的损失。这要求AI在训练时见到足够多的游戏状态和对手策略。

## 问题定义

以逆水寒武学试炼场景为例，敌我双方在圆形的场地上博弈。AI分为训练和测试两阶段，分别采用不同的配置以测试泛化能力。

### 对手策略规则
```
* pursue：模拟激进的攻击
	* 当有技能可用时，随机释放任意合法技能
	* 当无技能可用时，则靠近对手
* sly：保持一个较远的距离，偷偷攻击占便宜
	* 保持与对手的距离总在安全范围之内（保证对方普攻打不到自己，但自己至少有技能能够打到对方）
	* 若被对方技能打到，则提高安全范围的下界（可以加一个格子的距离=64），但最多不超过上界。
	* 在安全范围内靠近下界，随机选择合法的技能攻击对方
```

### 胜负标准

```
* 游戏过程中，若一方血量耗尽则判负
* 若游戏结束时双方都没死（血量>0），则根据游戏过程的累积伤害输出判定胜负。
```

### 配置
* 训练：双方均出生在场地中央。若算法需要游戏环境提供对手策略（PvE），则提供pursue对手陪练。
* 测试：双方出生在通过圆心的直线的最远端（角度随机）。分别测试AI在两种规则策略（pursue; sly）上的胜率。

## 评价指标

在测试配置上，评价AI对各种规则策略的胜率。

## 问题挑战

在训练和测试时，游戏环境的配置有显著的不同（出生点位）。即使采用self-play的方法，双方在非常接近的情况下容易学会战斗技能，但很难学会走位。缺乏走位意识的AI容易在测试阶段被找到弱点，被sly规则远距离占便宜。

从另一个角度来看，训练时双方容易站在圆心相互攻击，导致很多游戏状态难以学到。很难保证神经网络在碰到未知状态时仍能表现出泛化能力。

## 相关文献

* <https://www.nature.com/articles/s41586-019-1724-z>
* <https://arxiv.org/abs/1904.03821>
* <https://arxiv.org/abs/1812.07297>
* <https://arxiv.org/abs/1807.01281>
* <https://arxiv.org/abs/1907.03840>
* <https://www.ijcai.org/proceedings/2019/0176.pdf>
* <https://openreview.net/forum?id=HJz6QhR9YQ>

## 联系方式

* shenruimin@corp.netease.com
