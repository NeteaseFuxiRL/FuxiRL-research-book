# 课题背景

经典的模仿学习算法一般要求专家样本中的数据分布是一致的，但是在游戏场景下，从玩家处收集过来的数据往往属于不同的玩家，这些玩家的游戏风格也都是不尽相同的，其数据分布很有可能是多种多样的。

如何能够对游戏中收集得到的玩家数据进行自动的分类或者聚类，并模仿得到具有不同风格的策略模型，是本课题要解决的主要问题。

# 问题定义

假设已经有一个策略集合$\Pi=\{{\pi_1,\pi_2...,\pi_n\}}$。该策略集合中的一个或多个策略与环境互动后，可以收集到一个数据集$D=\{d_1,d_2...d_n\}$，其中的$d_i=\{(s_1,a_1), (s_2,a_2)...(s_m,a_m)\}$表示一系列的state和action数据对，每一个数据对表示了某个策略$\pi_d$在遇到状态$s_m$时会采取的动作$a_m$.

在有数据集$D$和环境的情况下，需要从数据集中学习得到原策略集合$\Pi$.

### 目标

1. 从由多种不同风格的策略产生的数据集中模仿得到各个不同风格的策略。

# 问题挑战

该问题主要存在以下几个挑战：

- 如何定义和度量不同的风格。
- 如何将收集到的数据对应到不同的风格上。
- 如何从不同风格的数据上学习到对应风格的策略。

# 环境支持

- 可以提供逆水寒游戏的流派竞武对战模拟环境。
- 可以提供逆水寒中收集到的在流派竞武对战场景中的玩家数据(state和action数据对)。

# 评价指标

- 学习得到的策略的基本强度，如技能释放成功率、胜率等。
- 学习得到的策略与对应风格的一致性（通过释放技能的分布等指标度量）。

# 相关学术论文

1. [2017- Robust Imitation of Diverse Behaviors](http://papers.nips.cc/paper/7116-robust-imitation-of-diverse-behaviors).

2. [2017- InfoGAIL: Interpretable Imitation Learning from Visual Demonstrations](http://papers.nips.cc/paper/6971-infogail-interpretable-imitation-learning-from-visual-demonstrations).

# 联系我们

有任何问题，请联系wangmeng02@corp.netease.com